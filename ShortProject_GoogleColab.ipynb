{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_representation_sp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atT567KhaLS5"
      },
      "source": [
        "# **Short project - Hand gesture recognition using the TAP**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-hWu0uUedLB"
      },
      "source": [
        "## **1.Data Handling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGzTM1sCaYIA"
      },
      "source": [
        "# Basic libraries\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from matplotlib import *\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# Dimensionality Reduction\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import decomposition\n",
        "\n",
        "# Performance Metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report                      \n",
        "\n",
        "# Classifiers\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn import svm                                                \n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Other libraries\n",
        "import plotly.graph_objects as go                                       \n",
        "import timeit"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "bpnBjQ23R71O",
        "outputId": "e13cfbae-7c37-4310-9315-94056607da0a"
      },
      "source": [
        "df = pd.read_csv('data_tap2.txt', delimiter = \",\")\n",
        "#df = pd.read_csv('/content/drive/MyDrive/Machine Learning & Pattern Recognition/short_project/data_tap.txt',delimiter=\",\")\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>acc1</th>\n",
              "      <th>acc2</th>\n",
              "      <th>acc3</th>\n",
              "      <th>acc4</th>\n",
              "      <th>acc5</th>\n",
              "      <th>acc6</th>\n",
              "      <th>acc7</th>\n",
              "      <th>acc8</th>\n",
              "      <th>acc9</th>\n",
              "      <th>acc10</th>\n",
              "      <th>acc11</th>\n",
              "      <th>acc12</th>\n",
              "      <th>acc13</th>\n",
              "      <th>acc14</th>\n",
              "      <th>acc15</th>\n",
              "      <th>simbology</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>32</td>\n",
              "      <td>6</td>\n",
              "      <td>-8</td>\n",
              "      <td>11</td>\n",
              "      <td>-7</td>\n",
              "      <td>30</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>32</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>30</td>\n",
              "      <td>9</td>\n",
              "      <td>-7</td>\n",
              "      <td>31</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>33</td>\n",
              "      <td>6</td>\n",
              "      <td>-9</td>\n",
              "      <td>12</td>\n",
              "      <td>-8</td>\n",
              "      <td>29</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>32</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>30</td>\n",
              "      <td>8</td>\n",
              "      <td>-7</td>\n",
              "      <td>31</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>33</td>\n",
              "      <td>5</td>\n",
              "      <td>-8</td>\n",
              "      <td>11</td>\n",
              "      <td>-7</td>\n",
              "      <td>30</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>31</td>\n",
              "      <td>8</td>\n",
              "      <td>-6</td>\n",
              "      <td>31</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>5</td>\n",
              "      <td>-8</td>\n",
              "      <td>11</td>\n",
              "      <td>-7</td>\n",
              "      <td>30</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>32</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>30</td>\n",
              "      <td>8</td>\n",
              "      <td>-7</td>\n",
              "      <td>31</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>33</td>\n",
              "      <td>5</td>\n",
              "      <td>-8</td>\n",
              "      <td>11</td>\n",
              "      <td>-7</td>\n",
              "      <td>30</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>32</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>31</td>\n",
              "      <td>7</td>\n",
              "      <td>-6</td>\n",
              "      <td>32</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   acc1  acc2  acc3  acc4  acc5  ...  acc12  acc13  acc14  acc15  simbology\n",
              "0    32     6    -8    11    -7  ...     30      9     -7     31          A\n",
              "1    33     6    -9    12    -8  ...     30      8     -7     31          A\n",
              "2    33     5    -8    11    -7  ...     31      8     -6     31          A\n",
              "3    33     5    -8    11    -7  ...     30      8     -7     31          A\n",
              "4    33     5    -8    11    -7  ...     31      7     -6     32          A\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2A-r9_jpluv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1d1210c-ec5a-4449-9f27-aeb15a5c47be"
      },
      "source": [
        "print(df.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4910, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "oIsYvwwaZkaD",
        "outputId": "063d5a25-9912-4c0c-ea88-9519ef562aad"
      },
      "source": [
        "# Eliminate the nan values\n",
        "df.dropna()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>acc1</th>\n",
              "      <th>acc2</th>\n",
              "      <th>acc3</th>\n",
              "      <th>acc4</th>\n",
              "      <th>acc5</th>\n",
              "      <th>acc6</th>\n",
              "      <th>acc7</th>\n",
              "      <th>acc8</th>\n",
              "      <th>acc9</th>\n",
              "      <th>acc10</th>\n",
              "      <th>acc11</th>\n",
              "      <th>acc12</th>\n",
              "      <th>acc13</th>\n",
              "      <th>acc14</th>\n",
              "      <th>acc15</th>\n",
              "      <th>simbology</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>32</td>\n",
              "      <td>6</td>\n",
              "      <td>-8</td>\n",
              "      <td>11</td>\n",
              "      <td>-7</td>\n",
              "      <td>30</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>32</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>30</td>\n",
              "      <td>9</td>\n",
              "      <td>-7</td>\n",
              "      <td>31</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>33</td>\n",
              "      <td>6</td>\n",
              "      <td>-9</td>\n",
              "      <td>12</td>\n",
              "      <td>-8</td>\n",
              "      <td>29</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>32</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>30</td>\n",
              "      <td>8</td>\n",
              "      <td>-7</td>\n",
              "      <td>31</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>33</td>\n",
              "      <td>5</td>\n",
              "      <td>-8</td>\n",
              "      <td>11</td>\n",
              "      <td>-7</td>\n",
              "      <td>30</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>31</td>\n",
              "      <td>8</td>\n",
              "      <td>-6</td>\n",
              "      <td>31</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>5</td>\n",
              "      <td>-8</td>\n",
              "      <td>11</td>\n",
              "      <td>-7</td>\n",
              "      <td>30</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>32</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>30</td>\n",
              "      <td>8</td>\n",
              "      <td>-7</td>\n",
              "      <td>31</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>33</td>\n",
              "      <td>5</td>\n",
              "      <td>-8</td>\n",
              "      <td>11</td>\n",
              "      <td>-7</td>\n",
              "      <td>30</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>32</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>31</td>\n",
              "      <td>7</td>\n",
              "      <td>-6</td>\n",
              "      <td>32</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4905</th>\n",
              "      <td>31</td>\n",
              "      <td>-3</td>\n",
              "      <td>11</td>\n",
              "      <td>22</td>\n",
              "      <td>6</td>\n",
              "      <td>24</td>\n",
              "      <td>30</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "      <td>18</td>\n",
              "      <td>8</td>\n",
              "      <td>25</td>\n",
              "      <td>8</td>\n",
              "      <td>18</td>\n",
              "      <td>*</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4906</th>\n",
              "      <td>31</td>\n",
              "      <td>-3</td>\n",
              "      <td>15</td>\n",
              "      <td>21</td>\n",
              "      <td>9</td>\n",
              "      <td>24</td>\n",
              "      <td>29</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>21</td>\n",
              "      <td>5</td>\n",
              "      <td>23</td>\n",
              "      <td>13</td>\n",
              "      <td>18</td>\n",
              "      <td>*</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4907</th>\n",
              "      <td>29</td>\n",
              "      <td>-6</td>\n",
              "      <td>16</td>\n",
              "      <td>21</td>\n",
              "      <td>9</td>\n",
              "      <td>24</td>\n",
              "      <td>30</td>\n",
              "      <td>11</td>\n",
              "      <td>-2</td>\n",
              "      <td>25</td>\n",
              "      <td>20</td>\n",
              "      <td>4</td>\n",
              "      <td>26</td>\n",
              "      <td>12</td>\n",
              "      <td>17</td>\n",
              "      <td>*</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4908</th>\n",
              "      <td>29</td>\n",
              "      <td>-8</td>\n",
              "      <td>14</td>\n",
              "      <td>18</td>\n",
              "      <td>8</td>\n",
              "      <td>25</td>\n",
              "      <td>29</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>22</td>\n",
              "      <td>20</td>\n",
              "      <td>7</td>\n",
              "      <td>23</td>\n",
              "      <td>12</td>\n",
              "      <td>18</td>\n",
              "      <td>*</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4909</th>\n",
              "      <td>29</td>\n",
              "      <td>-9</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>17</td>\n",
              "      <td>25</td>\n",
              "      <td>31</td>\n",
              "      <td>18</td>\n",
              "      <td>-3</td>\n",
              "      <td>24</td>\n",
              "      <td>26</td>\n",
              "      <td>2</td>\n",
              "      <td>26</td>\n",
              "      <td>19</td>\n",
              "      <td>18</td>\n",
              "      <td>*</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4910 rows × 16 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      acc1  acc2  acc3  acc4  acc5  ...  acc12  acc13  acc14  acc15  simbology\n",
              "0       32     6    -8    11    -7  ...     30      9     -7     31          A\n",
              "1       33     6    -9    12    -8  ...     30      8     -7     31          A\n",
              "2       33     5    -8    11    -7  ...     31      8     -6     31          A\n",
              "3       33     5    -8    11    -7  ...     30      8     -7     31          A\n",
              "4       33     5    -8    11    -7  ...     31      7     -6     32          A\n",
              "...    ...   ...   ...   ...   ...  ...    ...    ...    ...    ...        ...\n",
              "4905    31    -3    11    22     6  ...      8     25      8     18          *\n",
              "4906    31    -3    15    21     9  ...      5     23     13     18          *\n",
              "4907    29    -6    16    21     9  ...      4     26     12     17          *\n",
              "4908    29    -8    14    18     8  ...      7     23     12     18          *\n",
              "4909    29    -9    20    20    17  ...      2     26     19     18          *\n",
              "\n",
              "[4910 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76NBUIvWLtmY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76ec09ef-416d-4755-a02f-d6e1cbdeb505"
      },
      "source": [
        "# Change the string values in simbology to int values:\n",
        "df['simbology'] = df['simbology'].replace(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J4', 'K', 'L', 'M', 'N',\n",
        "                                               'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '*'],\n",
        "                                              [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,\n",
        "                                               14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27])\n",
        "true_simbology = df['simbology']\n",
        "true_simbology"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        1\n",
              "1        1\n",
              "2        1\n",
              "3        1\n",
              "4        1\n",
              "        ..\n",
              "4905    27\n",
              "4906    27\n",
              "4907    27\n",
              "4908    27\n",
              "4909    27\n",
              "Name: simbology, Length: 4910, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1idmUrSqz03"
      },
      "source": [
        "## **2. Dimensionality Reduction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WrnEtmaqx37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "outputId": "157ca393-0a90-41ef-b460-671ce6d8ce85"
      },
      "source": [
        "# 1) Normalize the data\n",
        "D = df.iloc[:,:-1].to_numpy()\n",
        "D_st= StandardScaler().fit_transform(D)\n",
        "pd.DataFrame(D_st)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.002298</td>\n",
              "      <td>1.748204</td>\n",
              "      <td>-0.619942</td>\n",
              "      <td>-0.446031</td>\n",
              "      <td>-1.513200</td>\n",
              "      <td>1.239762</td>\n",
              "      <td>-0.504859</td>\n",
              "      <td>-1.028903</td>\n",
              "      <td>1.667274</td>\n",
              "      <td>-0.295250</td>\n",
              "      <td>-2.085835</td>\n",
              "      <td>1.745051</td>\n",
              "      <td>-0.333559</td>\n",
              "      <td>-2.669101</td>\n",
              "      <td>1.525393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.097862</td>\n",
              "      <td>1.748204</td>\n",
              "      <td>-0.687835</td>\n",
              "      <td>-0.371358</td>\n",
              "      <td>-1.602376</td>\n",
              "      <td>1.157865</td>\n",
              "      <td>-0.504859</td>\n",
              "      <td>-1.028903</td>\n",
              "      <td>1.667274</td>\n",
              "      <td>-0.295250</td>\n",
              "      <td>-2.085835</td>\n",
              "      <td>1.745051</td>\n",
              "      <td>-0.402661</td>\n",
              "      <td>-2.669101</td>\n",
              "      <td>1.525393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.097862</td>\n",
              "      <td>1.657534</td>\n",
              "      <td>-0.619942</td>\n",
              "      <td>-0.446031</td>\n",
              "      <td>-1.513200</td>\n",
              "      <td>1.239762</td>\n",
              "      <td>-0.504859</td>\n",
              "      <td>-0.905197</td>\n",
              "      <td>1.667274</td>\n",
              "      <td>-0.295250</td>\n",
              "      <td>-2.085835</td>\n",
              "      <td>1.824909</td>\n",
              "      <td>-0.402661</td>\n",
              "      <td>-2.549003</td>\n",
              "      <td>1.525393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.097862</td>\n",
              "      <td>1.657534</td>\n",
              "      <td>-0.619942</td>\n",
              "      <td>-0.446031</td>\n",
              "      <td>-1.513200</td>\n",
              "      <td>1.239762</td>\n",
              "      <td>-0.566687</td>\n",
              "      <td>-1.028903</td>\n",
              "      <td>1.667274</td>\n",
              "      <td>-0.295250</td>\n",
              "      <td>-2.085835</td>\n",
              "      <td>1.745051</td>\n",
              "      <td>-0.402661</td>\n",
              "      <td>-2.669101</td>\n",
              "      <td>1.525393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.097862</td>\n",
              "      <td>1.657534</td>\n",
              "      <td>-0.619942</td>\n",
              "      <td>-0.446031</td>\n",
              "      <td>-1.513200</td>\n",
              "      <td>1.239762</td>\n",
              "      <td>-0.566687</td>\n",
              "      <td>-1.028903</td>\n",
              "      <td>1.667274</td>\n",
              "      <td>-0.359907</td>\n",
              "      <td>-1.913559</td>\n",
              "      <td>1.824909</td>\n",
              "      <td>-0.471762</td>\n",
              "      <td>-2.549003</td>\n",
              "      <td>1.624745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4905</th>\n",
              "      <td>0.906733</td>\n",
              "      <td>0.932178</td>\n",
              "      <td>0.670025</td>\n",
              "      <td>0.375373</td>\n",
              "      <td>-0.353908</td>\n",
              "      <td>0.748381</td>\n",
              "      <td>0.979007</td>\n",
              "      <td>-0.657784</td>\n",
              "      <td>-0.679828</td>\n",
              "      <td>0.609950</td>\n",
              "      <td>-0.190802</td>\n",
              "      <td>-0.011824</td>\n",
              "      <td>0.772065</td>\n",
              "      <td>-0.867621</td>\n",
              "      <td>0.233812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4906</th>\n",
              "      <td>0.906733</td>\n",
              "      <td>0.932178</td>\n",
              "      <td>0.941597</td>\n",
              "      <td>0.300700</td>\n",
              "      <td>-0.086379</td>\n",
              "      <td>0.748381</td>\n",
              "      <td>0.917179</td>\n",
              "      <td>-0.286666</td>\n",
              "      <td>-0.755541</td>\n",
              "      <td>0.674608</td>\n",
              "      <td>0.326026</td>\n",
              "      <td>-0.251398</td>\n",
              "      <td>0.633862</td>\n",
              "      <td>-0.267128</td>\n",
              "      <td>0.233812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4907</th>\n",
              "      <td>0.715604</td>\n",
              "      <td>0.660170</td>\n",
              "      <td>1.009490</td>\n",
              "      <td>0.300700</td>\n",
              "      <td>-0.086379</td>\n",
              "      <td>0.748381</td>\n",
              "      <td>0.979007</td>\n",
              "      <td>-0.534078</td>\n",
              "      <td>-0.906967</td>\n",
              "      <td>0.803922</td>\n",
              "      <td>0.153750</td>\n",
              "      <td>-0.331256</td>\n",
              "      <td>0.841167</td>\n",
              "      <td>-0.387227</td>\n",
              "      <td>0.134460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4908</th>\n",
              "      <td>0.715604</td>\n",
              "      <td>0.478831</td>\n",
              "      <td>0.873704</td>\n",
              "      <td>0.076681</td>\n",
              "      <td>-0.175556</td>\n",
              "      <td>0.830277</td>\n",
              "      <td>0.917179</td>\n",
              "      <td>-0.534078</td>\n",
              "      <td>-0.604115</td>\n",
              "      <td>0.609950</td>\n",
              "      <td>0.153750</td>\n",
              "      <td>-0.091682</td>\n",
              "      <td>0.633862</td>\n",
              "      <td>-0.387227</td>\n",
              "      <td>0.233812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4909</th>\n",
              "      <td>0.715604</td>\n",
              "      <td>0.388161</td>\n",
              "      <td>1.281062</td>\n",
              "      <td>0.226027</td>\n",
              "      <td>0.627031</td>\n",
              "      <td>0.830277</td>\n",
              "      <td>1.040834</td>\n",
              "      <td>0.331865</td>\n",
              "      <td>-0.982680</td>\n",
              "      <td>0.739265</td>\n",
              "      <td>1.187404</td>\n",
              "      <td>-0.490972</td>\n",
              "      <td>0.841167</td>\n",
              "      <td>0.453464</td>\n",
              "      <td>0.233812</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4910 rows × 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0         1         2   ...        12        13        14\n",
              "0     1.002298  1.748204 -0.619942  ... -0.333559 -2.669101  1.525393\n",
              "1     1.097862  1.748204 -0.687835  ... -0.402661 -2.669101  1.525393\n",
              "2     1.097862  1.657534 -0.619942  ... -0.402661 -2.549003  1.525393\n",
              "3     1.097862  1.657534 -0.619942  ... -0.402661 -2.669101  1.525393\n",
              "4     1.097862  1.657534 -0.619942  ... -0.471762 -2.549003  1.624745\n",
              "...        ...       ...       ...  ...       ...       ...       ...\n",
              "4905  0.906733  0.932178  0.670025  ...  0.772065 -0.867621  0.233812\n",
              "4906  0.906733  0.932178  0.941597  ...  0.633862 -0.267128  0.233812\n",
              "4907  0.715604  0.660170  1.009490  ...  0.841167 -0.387227  0.134460\n",
              "4908  0.715604  0.478831  0.873704  ...  0.633862 -0.387227  0.233812\n",
              "4909  0.715604  0.388161  1.281062  ...  0.841167  0.453464  0.233812\n",
              "\n",
              "[4910 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "65IBrNbYbKzN",
        "outputId": "2cd92011-a4d8-4452-9df8-339707920dfb"
      },
      "source": [
        "# 2) Apply a decomposition analysis to all the features to observe the variance\n",
        "pca = decomposition.PCA(n_components=14).fit(D_st)\n",
        "exp_var = 100*pca.explained_variance_ratio_.cumsum()\n",
        "\n",
        "# Plot the explained variance as a function of the components\n",
        "plt.plot(exp_var,np.arange(1, 15, 1))\n",
        "plt.grid()\n",
        "plt.xlabel('Explained variance')\n",
        "plt.ylabel('Number of components')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Number of components')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lx7T_1duU_NX",
        "outputId": "04568c23-1c9c-4bcb-b0eb-d083b5f0b272"
      },
      "source": [
        "# Explained variance taking (4, 5 or 6) components\n",
        "print('The 4th PCA component explains {} % of the variability of the data'.format(exp_var[3]))\n",
        "print('The 5th PCA component explains {} % of the variability of the data'.format(exp_var[4]))\n",
        "print('The 6th PCA component explains {} % of the variability of the data'.format(exp_var[5]))\n",
        "\n",
        "pca_4comp = decomposition.PCA(n_components=4).fit(D_st)\n",
        "pca_5comp = decomposition.PCA(n_components=5).fit(D_st)\n",
        "pca_6comp = decomposition.PCA(n_components=6).fit(D_st)\n",
        "\n",
        "# Chose the amount of components to visualize the accuracies later\n",
        "pca = pca_5comp"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The 4th PCA component explains 86.69628772484569 % of the variability of the data\n",
            "The 5th PCA component explains 91.0323005376687 % of the variability of the data\n",
            "The 6th PCA component explains 94.86018352619156 % of the variability of the data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjN_YbD5oT78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aab058c3-ec49-4422-b11d-d75ece72dcee"
      },
      "source": [
        "# Data projected\n",
        "Xproj = pca.transform(D_st) \n",
        "print(Xproj.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4910, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMolcNstpKH2"
      },
      "source": [
        "We projected our dataset features dimensions from 21 to 15 (eliminating the imu values), and from 15 to 5 (performing a PCA). With 5 dimensions we are able to compress more than 90% of the variance of our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apzakaqcphRC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "ea463ece-844a-431d-a4b2-09770d2e21b7"
      },
      "source": [
        "Xproj = pd.DataFrame(Xproj)\n",
        "Xproj['symbols'] = df['simbology']\n",
        "Xproj = shuffle(Xproj)\n",
        "Xproj"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>symbols</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4594</th>\n",
              "      <td>-1.643444</td>\n",
              "      <td>-2.906104</td>\n",
              "      <td>0.795698</td>\n",
              "      <td>-0.353852</td>\n",
              "      <td>0.944956</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4494</th>\n",
              "      <td>-1.204968</td>\n",
              "      <td>0.117731</td>\n",
              "      <td>0.055079</td>\n",
              "      <td>2.054404</td>\n",
              "      <td>1.604996</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3449</th>\n",
              "      <td>0.382489</td>\n",
              "      <td>0.925134</td>\n",
              "      <td>-1.875030</td>\n",
              "      <td>0.416503</td>\n",
              "      <td>-0.013510</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3973</th>\n",
              "      <td>0.014571</td>\n",
              "      <td>-1.515505</td>\n",
              "      <td>-0.558300</td>\n",
              "      <td>-1.466472</td>\n",
              "      <td>0.749050</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170</th>\n",
              "      <td>-2.405810</td>\n",
              "      <td>1.430056</td>\n",
              "      <td>-0.040458</td>\n",
              "      <td>-1.124748</td>\n",
              "      <td>0.823098</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1134</th>\n",
              "      <td>5.047967</td>\n",
              "      <td>-1.879849</td>\n",
              "      <td>0.121635</td>\n",
              "      <td>1.212388</td>\n",
              "      <td>-0.257297</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4115</th>\n",
              "      <td>-1.612848</td>\n",
              "      <td>-2.442198</td>\n",
              "      <td>1.324930</td>\n",
              "      <td>-1.463302</td>\n",
              "      <td>0.003462</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2446</th>\n",
              "      <td>-1.512631</td>\n",
              "      <td>1.138960</td>\n",
              "      <td>-1.513265</td>\n",
              "      <td>-0.189716</td>\n",
              "      <td>-0.877006</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1460</th>\n",
              "      <td>-2.174386</td>\n",
              "      <td>-0.008311</td>\n",
              "      <td>-0.125569</td>\n",
              "      <td>2.654241</td>\n",
              "      <td>0.114270</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2727</th>\n",
              "      <td>3.369828</td>\n",
              "      <td>2.218299</td>\n",
              "      <td>0.689457</td>\n",
              "      <td>-0.077462</td>\n",
              "      <td>-0.136117</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4910 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             0         1         2         3         4  symbols\n",
              "4594 -1.643444 -2.906104  0.795698 -0.353852  0.944956       26\n",
              "4494 -1.204968  0.117731  0.055079  2.054404  1.604996       25\n",
              "3449  0.382489  0.925134 -1.875030  0.416503 -0.013510       20\n",
              "3973  0.014571 -1.515505 -0.558300 -1.466472  0.749050       22\n",
              "170  -2.405810  1.430056 -0.040458 -1.124748  0.823098        4\n",
              "...        ...       ...       ...       ...       ...      ...\n",
              "1134  5.047967 -1.879849  0.121635  1.212388 -0.257297        8\n",
              "4115 -1.612848 -2.442198  1.324930 -1.463302  0.003462       23\n",
              "2446 -1.512631  1.138960 -1.513265 -0.189716 -0.877006       14\n",
              "1460 -2.174386 -0.008311 -0.125569  2.654241  0.114270        9\n",
              "2727  3.369828  2.218299  0.689457 -0.077462 -0.136117       16\n",
              "\n",
              "[4910 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcia3YEVvMlJ"
      },
      "source": [
        "## **3. Classifiers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vr76YCVddyzF"
      },
      "source": [
        "# Without PCA -> consider df \n",
        "# With PCA -> consider Xproj\n",
        "\n",
        "# keep only numeric variables \n",
        "df_num = Xproj.select_dtypes(include='number') "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmYd1xp2eIR2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "92927607-8699-445a-ff6b-3564681bb774"
      },
      "source": [
        "# Define the train dataset (70%) and the test dataset (30%)\n",
        "[row, col] = df_num.shape\n",
        "training_rows = math.ceil(row*.7)\n",
        "testing_rows = math.floor(row*.3)\n",
        "\n",
        "# trainX, testX, trainY, testY = train_test_split( X, Y, test_size = 0.3)\n",
        "data_train = df_num.iloc[:training_rows,:col-1]\n",
        "label_train = df_num.iloc[:training_rows,col-1:]\n",
        "data_test = df_num.iloc[training_rows:,:col-1]\n",
        "label_test = df_num.iloc[training_rows:,col-1:]\n",
        "label_test"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>symbols</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1841</th>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3927</th>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>422</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4695</th>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4348</th>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1134</th>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4115</th>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2446</th>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1460</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2727</th>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1473 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      symbols\n",
              "1841       11\n",
              "3927       22\n",
              "422         5\n",
              "4695       26\n",
              "4348       25\n",
              "...       ...\n",
              "1134        8\n",
              "4115       23\n",
              "2446       14\n",
              "1460        9\n",
              "2727       16\n",
              "\n",
              "[1473 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9ZAZh7qcSl6"
      },
      "source": [
        "### Linear Discriminant Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OlIgfJVqyJr"
      },
      "source": [
        "# Training the model \n",
        "#clf_lda = LinearDiscriminantAnalysis(n_components=27,priors=None)  \n",
        "clf_lda = LinearDiscriminantAnalysis(n_components=5,priors=None)\n",
        "#clf_lda.fit(data_train, label_train)                               #Miguel: linea cambiada por la siguiente \n",
        "clf_lda.fit(data_train, label_train['symbols'].values)\n",
        "\n",
        "# Predict with test data\n",
        "label_predicted_lda = clf_lda.predict(data_test)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OP4PCnv8jSyf",
        "outputId": "147ae2b6-2da5-4724-a1b7-5e25c146627a"
      },
      "source": [
        "# Accuracy score\n",
        "accur1 = accuracy_score(label_test, label_predicted_lda)\n",
        "print('The accuracy of the LDA is: {} %'.format(accur1*100))\n",
        "\n",
        "LDA_4comp = 91.17\n",
        "LDA_5comp = 97.02\n",
        "LDA_6comp = 97.14"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy of the LDA is: 97.21656483367278 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CI15kWljFrV"
      },
      "source": [
        "### Quadratic Discriminant Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEZhOLgGi8eg"
      },
      "source": [
        "# Training the model \n",
        "clf_qda = QuadraticDiscriminantAnalysis(priors=None)\n",
        "#clf_qda.fit(data_train, label_train)                                 \n",
        "clf_qda.fit(data_train, label_train['symbols'].values)\n",
        "\n",
        "# Predict with test data\n",
        "label_predicted_qda = clf_qda.predict(data_test)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VrCIgVzjJPV",
        "outputId": "88421056-e1ca-4830-ffe4-da2d94729dfa"
      },
      "source": [
        "# Accuracy score\n",
        "accur2 = accuracy_score(label_test, label_predicted_qda)\n",
        "print('The accuracy of the QDA is: {} %'.format(accur2*100))\n",
        "\n",
        "QDA_4comp = 97.21\n",
        "QDA_5comp = 98.98\n",
        "QDA_6comp = 99.11"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy of the QDA is: 99.45689069925322 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOTJe2rFzIt9"
      },
      "source": [
        "### Support Vector Machines\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HOJ2KfyWHdS"
      },
      "source": [
        "SVC implements the “one-versus-one” approach for multi-class classification. In total, n_classes * (n_classes - 1) / 2 classifiers are constructed and each one trains data from two classes. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4r0Y7G_zYLA",
        "outputId": "96b02d66-5a23-4a3a-bd16-b3dfd325b9ec"
      },
      "source": [
        "support = svm.SVC() \n",
        "support.fit(data_train, label_train['symbols'].values)\n",
        "print('The accuracy of the SVM is: {} %'.format(100*support.score(data_test, label_test)))\n",
        "\n",
        "label_predicted_svm = support.predict(data_test)\n",
        "\n",
        "svm_4comp = 94.84\n",
        "svm_5comp = 99.18\n",
        "svm_6comp = 98.98"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy of the SVM is: 98.98167006109979 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEms-M-kU6Hs"
      },
      "source": [
        "In support vector machines, the line that maximizes this margin is the one we will choose as the optimal model. Support vector machines are an example of such a maximum margin estimator. We will use Scikit-Learn's support vector classifier to train an SVM model on this data. \n",
        "A key to this classifier's success is that for the fit, only the position of the support vectors matter; any points further from the margin which are on the correct side do not modify the fit! Technically, this is because these points do not contribute to the loss function used to fit the model, so their position and number do not matter so long as they do not cross the margin.\n",
        "\n",
        "The advantages of support vector machines are:\n",
        "\n",
        "*  Effective in high dimensional spaces.\n",
        "\n",
        "*  Still effective in cases where number of dimensions is greater than the number of samples.\n",
        "\n",
        "*  Uses a subset of training points in the decision function (called support vectors), so it is also memory efficient."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7kBeBlPYPqF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "cf735f3b-d6ae-49e4-e21f-963480c3aed1"
      },
      "source": [
        "# The localization of the support vectors\n",
        "pd.DataFrame(support.support_vectors_) "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-3.480831</td>\n",
              "      <td>2.578625</td>\n",
              "      <td>1.422329</td>\n",
              "      <td>0.128717</td>\n",
              "      <td>-0.496587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-3.302113</td>\n",
              "      <td>2.828317</td>\n",
              "      <td>1.132090</td>\n",
              "      <td>-0.025150</td>\n",
              "      <td>-0.562073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-2.134368</td>\n",
              "      <td>4.178775</td>\n",
              "      <td>0.432562</td>\n",
              "      <td>0.324965</td>\n",
              "      <td>-1.064677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-3.046697</td>\n",
              "      <td>3.892114</td>\n",
              "      <td>0.875275</td>\n",
              "      <td>-0.522514</td>\n",
              "      <td>-0.924044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-2.129320</td>\n",
              "      <td>3.671643</td>\n",
              "      <td>-0.392037</td>\n",
              "      <td>0.445573</td>\n",
              "      <td>-0.908453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1193</th>\n",
              "      <td>-3.540548</td>\n",
              "      <td>-1.284515</td>\n",
              "      <td>0.692667</td>\n",
              "      <td>0.649897</td>\n",
              "      <td>-1.413113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1194</th>\n",
              "      <td>-1.699958</td>\n",
              "      <td>-0.512964</td>\n",
              "      <td>-1.241499</td>\n",
              "      <td>0.314936</td>\n",
              "      <td>-1.069390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1195</th>\n",
              "      <td>-3.058037</td>\n",
              "      <td>-0.321554</td>\n",
              "      <td>-0.368477</td>\n",
              "      <td>0.508304</td>\n",
              "      <td>-1.798974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1196</th>\n",
              "      <td>-2.334572</td>\n",
              "      <td>0.320285</td>\n",
              "      <td>-0.295670</td>\n",
              "      <td>0.034361</td>\n",
              "      <td>-1.315837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1197</th>\n",
              "      <td>-2.133958</td>\n",
              "      <td>-0.677803</td>\n",
              "      <td>-0.906372</td>\n",
              "      <td>0.322953</td>\n",
              "      <td>-1.171939</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1198 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             0         1         2         3         4\n",
              "0    -3.480831  2.578625  1.422329  0.128717 -0.496587\n",
              "1    -3.302113  2.828317  1.132090 -0.025150 -0.562073\n",
              "2    -2.134368  4.178775  0.432562  0.324965 -1.064677\n",
              "3    -3.046697  3.892114  0.875275 -0.522514 -0.924044\n",
              "4    -2.129320  3.671643 -0.392037  0.445573 -0.908453\n",
              "...        ...       ...       ...       ...       ...\n",
              "1193 -3.540548 -1.284515  0.692667  0.649897 -1.413113\n",
              "1194 -1.699958 -0.512964 -1.241499  0.314936 -1.069390\n",
              "1195 -3.058037 -0.321554 -0.368477  0.508304 -1.798974\n",
              "1196 -2.334572  0.320285 -0.295670  0.034361 -1.315837\n",
              "1197 -2.133958 -0.677803 -0.906372  0.322953 -1.171939\n",
              "\n",
              "[1198 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siuOXEdUWfi0",
        "outputId": "763a45ae-84c0-4004-cf5d-d5063ead406b"
      },
      "source": [
        "# Only x points are important in order to build the classifier\n",
        "support.dual_coef_.sum()\n",
        "# If he sum is equal to 0; then it is well balanced"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUkdf936UGVZ",
        "outputId": "b2125110-4acf-479c-967a-dee598bc1bfa"
      },
      "source": [
        "# indices of support vectors\n",
        "support.support_"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 151,  868, 1149, ..., 3396, 3427, 3431], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpWLG7PZV53_",
        "outputId": "208f819b-03c9-4893-93f4-08c31933d5f3"
      },
      "source": [
        "# get number of support vectors for each class\n",
        "support.n_support_"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([17, 22, 24, 38, 71, 25, 38, 32, 58, 50, 46, 35, 74, 75, 73, 39, 31,\n",
              "       17, 43, 74, 68, 43, 51, 21, 44, 33, 56], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvZN2V5q03Mb"
      },
      "source": [
        "### Random forests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnaY30qM05Fn",
        "outputId": "15cb3ecc-f887-4012-dd52-e5530da5b6ed"
      },
      "source": [
        "forest = RandomForestClassifier()\n",
        "#forest.fit(data_train, label_train)                         \n",
        "forest.fit(data_train, label_train['symbols'].values)\n",
        "print('The accuracy of the RandomForest is: {} %'.format(100*forest.score(data_test, label_test)))\n",
        "\n",
        "label_predicted_rf = forest.predict(data_test)\n",
        "\n",
        "rf_4comp = 96.87\n",
        "rf_5comp = 98.84\n",
        "rf_6comp = 99.11"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy of the RandomForest is: 99.38900203665987 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0kQMvLIqfpV"
      },
      "source": [
        "## **4. Performance Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "XbUdkQhuql8E",
        "outputId": "ab29763c-83cc-4649-b61b-3b06a8569c83"
      },
      "source": [
        "# Accuracy of each classifier depending on the dimensions used for the PCA\n",
        "fig = go.Figure(data=[go.Table(header=dict(values=['PCA dimensions','LDA', 'QDA', 'SVM', 'RF']),\n",
        "                 cells=dict(values=[['4', '5', '6'], [LDA_4comp, LDA_5comp, LDA_6comp], [QDA_4comp, QDA_5comp, QDA_6comp], \n",
        "                                    [svm_4comp, svm_5comp, svm_6comp], [rf_4comp, rf_5comp, rf_6comp]]))])\n",
        "fig.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"3b79d838-0676-4284-a01a-dd6247706b39\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"3b79d838-0676-4284-a01a-dd6247706b39\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '3b79d838-0676-4284-a01a-dd6247706b39',\n",
              "                        [{\"cells\": {\"values\": [[\"4\", \"5\", \"6\"], [91.17, 97.02, 97.14], [97.21, 98.98, 99.11], [94.84, 99.18, 98.98], [96.87, 98.84, 99.11]]}, \"header\": {\"values\": [\"PCA dimensions\", \"LDA\", \"QDA\", \"SVM\", \"RF\"]}, \"type\": \"table\"}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('3b79d838-0676-4284-a01a-dd6247706b39');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRG30w_aJaIz"
      },
      "source": [
        "### Classification reports\n",
        "We will obtain the classification report to check the different precision indices for each class. Because our classification problem is not binary, the accuracy is not calculated: there will not be true negative and true positive samples, only \"correctly classified\" and \"not correctly classified\" samples. Instead, the macro and weighted average accuracy of each class will be taken into account. The same applies for recall index."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeYsekAIISbD",
        "outputId": "4b22c8d3-5f4e-4d16-b1c6-b5b03ed055fe"
      },
      "source": [
        "# LDA Classification report\n",
        "print(classification_report(label_test, label_predicted_lda))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       1.00      1.00      1.00        15\n",
            "           3       1.00      1.00      1.00        15\n",
            "           4       0.94      1.00      0.97        16\n",
            "           5       0.99      0.97      0.98        92\n",
            "           6       1.00      0.99      0.99        93\n",
            "           7       1.00      0.98      0.99        63\n",
            "           8       0.99      1.00      0.99        80\n",
            "           9       1.00      0.94      0.97        70\n",
            "          10       0.98      1.00      0.99        63\n",
            "          11       0.98      1.00      0.99        53\n",
            "          12       1.00      0.99      0.99        70\n",
            "          13       1.00      0.86      0.92        56\n",
            "          14       1.00      0.96      0.98        49\n",
            "          15       0.94      0.98      0.96        59\n",
            "          16       1.00      0.86      0.92        56\n",
            "          17       0.89      1.00      0.94        64\n",
            "          18       1.00      1.00      1.00        18\n",
            "          19       0.88      1.00      0.93        84\n",
            "          20       0.95      0.87      0.91        63\n",
            "          21       1.00      0.98      0.99        54\n",
            "          22       0.96      1.00      0.98        50\n",
            "          23       1.00      0.95      0.97        56\n",
            "          24       1.00      1.00      1.00        59\n",
            "          25       0.93      1.00      0.97        56\n",
            "          26       1.00      1.00      1.00        48\n",
            "          27       0.95      1.00      0.97        58\n",
            "\n",
            "    accuracy                           0.97      1473\n",
            "   macro avg       0.98      0.98      0.98      1473\n",
            "weighted avg       0.97      0.97      0.97      1473\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUNSJ2rVMB3x",
        "outputId": "31997bfa-aeb4-4729-fb29-e361c994a7e5"
      },
      "source": [
        "# QDA Classification report\n",
        "print(classification_report(label_test, label_predicted_qda))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.93      1.00      0.96        13\n",
            "           2       1.00      1.00      1.00        15\n",
            "           3       1.00      1.00      1.00        15\n",
            "           4       1.00      0.94      0.97        16\n",
            "           5       0.98      0.98      0.98        92\n",
            "           6       1.00      1.00      1.00        93\n",
            "           7       0.98      1.00      0.99        63\n",
            "           8       1.00      1.00      1.00        80\n",
            "           9       1.00      1.00      1.00        70\n",
            "          10       0.98      1.00      0.99        63\n",
            "          11       1.00      1.00      1.00        53\n",
            "          12       1.00      1.00      1.00        70\n",
            "          13       0.98      1.00      0.99        56\n",
            "          14       1.00      1.00      1.00        49\n",
            "          15       0.97      0.97      0.97        59\n",
            "          16       1.00      1.00      1.00        56\n",
            "          17       1.00      1.00      1.00        64\n",
            "          18       1.00      0.94      0.97        18\n",
            "          19       1.00      0.99      0.99        84\n",
            "          20       1.00      1.00      1.00        63\n",
            "          21       1.00      1.00      1.00        54\n",
            "          22       1.00      1.00      1.00        50\n",
            "          23       1.00      0.98      0.99        56\n",
            "          24       1.00      1.00      1.00        59\n",
            "          25       1.00      1.00      1.00        56\n",
            "          26       1.00      1.00      1.00        48\n",
            "          27       1.00      1.00      1.00        58\n",
            "\n",
            "    accuracy                           0.99      1473\n",
            "   macro avg       0.99      0.99      0.99      1473\n",
            "weighted avg       0.99      0.99      0.99      1473\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQQMURuRMNrT",
        "outputId": "bd3dc03d-1f46-4cb5-9aca-642a476a9cee"
      },
      "source": [
        "# SVM Classification report\n",
        "print(classification_report(label_test, label_predicted_svm))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       1.00      1.00      1.00        15\n",
            "           3       1.00      1.00      1.00        15\n",
            "           4       0.84      1.00      0.91        16\n",
            "           5       0.98      0.98      0.98        92\n",
            "           6       1.00      1.00      1.00        93\n",
            "           7       1.00      1.00      1.00        63\n",
            "           8       1.00      1.00      1.00        80\n",
            "           9       1.00      0.99      0.99        70\n",
            "          10       0.98      1.00      0.99        63\n",
            "          11       1.00      1.00      1.00        53\n",
            "          12       1.00      0.96      0.98        70\n",
            "          13       1.00      0.98      0.99        56\n",
            "          14       1.00      1.00      1.00        49\n",
            "          15       0.97      0.97      0.97        59\n",
            "          16       1.00      0.96      0.98        56\n",
            "          17       0.97      1.00      0.98        64\n",
            "          18       1.00      1.00      1.00        18\n",
            "          19       1.00      1.00      1.00        84\n",
            "          20       0.98      0.98      0.98        63\n",
            "          21       1.00      1.00      1.00        54\n",
            "          22       0.96      1.00      0.98        50\n",
            "          23       1.00      0.95      0.97        56\n",
            "          24       1.00      1.00      1.00        59\n",
            "          25       0.98      1.00      0.99        56\n",
            "          26       1.00      1.00      1.00        48\n",
            "          27       0.98      1.00      0.99        58\n",
            "\n",
            "    accuracy                           0.99      1473\n",
            "   macro avg       0.99      0.99      0.99      1473\n",
            "weighted avg       0.99      0.99      0.99      1473\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPYEqbpHMQK2",
        "outputId": "5faaa6d8-caed-4c5e-c3f8-e3722d3f4009"
      },
      "source": [
        "# RF Classification report\n",
        "print(classification_report(label_test, label_predicted_rf))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       1.00      1.00      1.00        15\n",
            "           3       0.94      1.00      0.97        15\n",
            "           4       0.94      0.94      0.94        16\n",
            "           5       0.99      1.00      0.99        92\n",
            "           6       1.00      1.00      1.00        93\n",
            "           7       0.97      1.00      0.98        63\n",
            "           8       1.00      1.00      1.00        80\n",
            "           9       1.00      0.99      0.99        70\n",
            "          10       0.98      1.00      0.99        63\n",
            "          11       1.00      1.00      1.00        53\n",
            "          12       1.00      0.99      0.99        70\n",
            "          13       1.00      1.00      1.00        56\n",
            "          14       1.00      1.00      1.00        49\n",
            "          15       1.00      0.98      0.99        59\n",
            "          16       1.00      1.00      1.00        56\n",
            "          17       1.00      1.00      1.00        64\n",
            "          18       1.00      0.89      0.94        18\n",
            "          19       1.00      1.00      1.00        84\n",
            "          20       1.00      1.00      1.00        63\n",
            "          21       1.00      1.00      1.00        54\n",
            "          22       0.96      1.00      0.98        50\n",
            "          23       1.00      0.95      0.97        56\n",
            "          24       1.00      1.00      1.00        59\n",
            "          25       0.98      1.00      0.99        56\n",
            "          26       1.00      1.00      1.00        48\n",
            "          27       1.00      1.00      1.00        58\n",
            "\n",
            "    accuracy                           0.99      1473\n",
            "   macro avg       0.99      0.99      0.99      1473\n",
            "weighted avg       0.99      0.99      0.99      1473\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIE3Asy0Vru3"
      },
      "source": [
        "### Confusion matrices\n",
        "A more detailed breakdown of the classification result is provided by the confusion matrices. These reflects in a clear manner the number of samples missclassified and with which classes are confused, and it is a very useful method when analysing performance. We will consider them as indicators of how and why we obtain such results from the cassification, rather than a method to obtain conclusive results on whether to choose one classifier or another."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1xE2kyLc3yx",
        "outputId": "a23f5f6e-4e0f-40bd-8703-ee0b68e5df7e"
      },
      "source": [
        "# LDA Confusion Matrix\n",
        "CM_LDA = confusion_matrix(label_test, label_predicted_lda)\n",
        "CM_LDA = pd.DataFrame(CM_LDA)\n",
        "CM_LDA.index = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N',\n",
        "                                               'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '*']\n",
        "print(CM_LDA)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   0   1   2   3   4   5   6   7   8   ...  18  19  20  21  22  23  24  25  26\n",
            "A  13   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "B   0  15   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "C   0   0  15   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "D   0   0   0  16   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "E   0   0   0   0  89   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "F   0   0   0   0   0  92   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "G   0   0   0   0   0   0  62   1   0  ...   0   0   0   0   0   0   0   0   0\n",
            "H   0   0   0   0   0   0   0  80   0  ...   0   0   0   0   0   0   0   0   0\n",
            "I   0   0   0   0   0   0   0   0  66  ...   0   0   0   0   0   0   4   0   0\n",
            "J   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "K   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "L   0   0   0   1   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "M   0   0   0   0   0   0   0   0   0  ...   5   1   0   0   0   0   0   0   2\n",
            "N   0   0   0   0   0   0   0   0   0  ...   0   2   0   0   0   0   0   0   0\n",
            "O   0   0   0   0   1   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "P   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "Q   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "R   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "S   0   0   0   0   0   0   0   0   0  ...  84   0   0   0   0   0   0   0   0\n",
            "T   0   0   0   0   0   0   0   0   0  ...   7  55   0   0   0   0   0   0   1\n",
            "U   0   0   0   0   0   0   0   0   0  ...   0   0  53   0   0   0   0   0   0\n",
            "V   0   0   0   0   0   0   0   0   0  ...   0   0   0  50   0   0   0   0   0\n",
            "W   0   0   0   0   0   0   0   0   0  ...   0   0   0   2  53   0   0   0   0\n",
            "X   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0  59   0   0   0\n",
            "Y   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0  56   0   0\n",
            "Z   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0  48   0\n",
            "*   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0  58\n",
            "\n",
            "[27 rows x 27 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_R6fK61FjJNn",
        "outputId": "6843c024-6ea3-4909-cc95-25759bdbeede"
      },
      "source": [
        "# QDA Confusion matrix\n",
        "CM_QDA = confusion_matrix(label_test, label_predicted_qda)\n",
        "CM_QDA = pd.DataFrame(CM_QDA)\n",
        "CM_QDA.index = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N',\n",
        "                                               'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '*']\n",
        "print(CM_QDA)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   0   1   2   3   4   5   6   7   8   ...  18  19  20  21  22  23  24  25  26\n",
            "A  13   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "B   0  15   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "C   0   0  15   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "D   1   0   0  15   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "E   0   0   0   0  90   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "F   0   0   0   0   0  93   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "G   0   0   0   0   0   0  63   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "H   0   0   0   0   0   0   0  80   0  ...   0   0   0   0   0   0   0   0   0\n",
            "I   0   0   0   0   0   0   0   0  70  ...   0   0   0   0   0   0   0   0   0\n",
            "J   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "K   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "L   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "M   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "N   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "O   0   0   0   0   2   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "P   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "Q   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "R   0   0   0   0   0   0   1   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "S   0   0   0   0   0   0   0   0   0  ...  83   0   0   0   0   0   0   0   0\n",
            "T   0   0   0   0   0   0   0   0   0  ...   0  63   0   0   0   0   0   0   0\n",
            "U   0   0   0   0   0   0   0   0   0  ...   0   0  54   0   0   0   0   0   0\n",
            "V   0   0   0   0   0   0   0   0   0  ...   0   0   0  50   0   0   0   0   0\n",
            "W   0   0   0   0   0   0   0   0   0  ...   0   0   0   0  55   0   0   0   0\n",
            "X   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0  59   0   0   0\n",
            "Y   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0  56   0   0\n",
            "Z   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0  48   0\n",
            "*   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0  58\n",
            "\n",
            "[27 rows x 27 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kx6VM_pziXL",
        "outputId": "0b2f84e5-9adb-4c6d-9ecb-60ae010843b2"
      },
      "source": [
        "# SVM Confusion matrix\n",
        "CM_SVM = confusion_matrix(label_test, label_predicted_svm)\n",
        "CM_SVM = pd.DataFrame(CM_SVM)\n",
        "CM_SVM.index = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N',\n",
        "                                               'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '*']\n",
        "print(CM_SVM)\n",
        "CM_SVM.to_csv (r'C:\\Users\\usuario1\\Dropbox\\MASTER\\export_dataframe.csv', index = False, header=True)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   0   1   2   3   4   5   6   7   8   ...  18  19  20  21  22  23  24  25  26\n",
            "A  13   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "B   0  15   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "C   0   0  15   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "D   0   0   0  16   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "E   0   0   0   0  90   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "F   0   0   0   0   0  93   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "G   0   0   0   0   0   0  63   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "H   0   0   0   0   0   0   0  80   0  ...   0   0   0   0   0   0   0   0   0\n",
            "I   0   0   0   0   0   0   0   0  69  ...   0   0   0   0   0   0   1   0   0\n",
            "J   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "K   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "L   0   0   0   3   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "M   0   0   0   0   0   0   0   0   0  ...   0   1   0   0   0   0   0   0   0\n",
            "N   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "O   0   0   0   0   2   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "P   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "Q   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "R   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "S   0   0   0   0   0   0   0   0   0  ...  84   0   0   0   0   0   0   0   0\n",
            "T   0   0   0   0   0   0   0   0   0  ...   0  62   0   0   0   0   0   0   1\n",
            "U   0   0   0   0   0   0   0   0   0  ...   0   0  54   0   0   0   0   0   0\n",
            "V   0   0   0   0   0   0   0   0   0  ...   0   0   0  50   0   0   0   0   0\n",
            "W   0   0   0   0   0   0   0   0   0  ...   0   0   0   2  53   0   0   0   0\n",
            "X   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0  59   0   0   0\n",
            "Y   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0  56   0   0\n",
            "Z   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0  48   0\n",
            "*   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0  58\n",
            "\n",
            "[27 rows x 27 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwu4a0V6zqEK",
        "outputId": "7a7df3b2-7c7b-4f4d-9964-56d27342f44b"
      },
      "source": [
        "# Confusion matrix\n",
        "CM_RF = confusion_matrix(label_test, label_predicted_rf)\n",
        "CM_RF= pd.DataFrame(CM_RF)\n",
        "CM_RF.index = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N',\n",
        "                                               'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '*']\n",
        "print(CM_RF)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   0   1   2   3   4   5   6   7   8   ...  18  19  20  21  22  23  24  25  26\n",
            "A  13   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "B   0  15   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "C   0   0  15   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "D   0   0   1  15   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "E   0   0   0   0  92   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "F   0   0   0   0   0  93   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "G   0   0   0   0   0   0  63   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "H   0   0   0   0   0   0   0  80   0  ...   0   0   0   0   0   0   0   0   0\n",
            "I   0   0   0   0   0   0   0   0  69  ...   0   0   0   0   0   0   1   0   0\n",
            "J   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "K   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "L   0   0   0   1   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "M   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "N   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "O   0   0   0   0   1   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "P   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "Q   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "R   0   0   0   0   0   0   2   0   0  ...   0   0   0   0   0   0   0   0   0\n",
            "S   0   0   0   0   0   0   0   0   0  ...  84   0   0   0   0   0   0   0   0\n",
            "T   0   0   0   0   0   0   0   0   0  ...   0  63   0   0   0   0   0   0   0\n",
            "U   0   0   0   0   0   0   0   0   0  ...   0   0  54   0   0   0   0   0   0\n",
            "V   0   0   0   0   0   0   0   0   0  ...   0   0   0  50   0   0   0   0   0\n",
            "W   0   0   0   0   0   0   0   0   0  ...   0   0   0   2  53   0   0   0   0\n",
            "X   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0  59   0   0   0\n",
            "Y   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0  56   0   0\n",
            "Z   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0  48   0\n",
            "*   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0  58\n",
            "\n",
            "[27 rows x 27 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giWHKNriOX4z"
      },
      "source": [
        "### Time performance\n",
        "Not only the results of the confisusion matrices and classification reports are important when studying the performance of a classifier. The time each classifier takes to finish the process of training and clasifying a given data set is also essential when deciding which one to use. For that reason a time performance analysis is carried out using **timeit()** python method from the **timeit** library. This method measures the execution time (in seconds) given by a certain code snippet. The number of iterations to run the desired portion of code will be set to 1000, in order to avoid extremely large execution times."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIO4G2O3Obyp",
        "outputId": "f2931f5a-ad45-4d69-e669-969ef5ef8491"
      },
      "source": [
        "# LDA time performance analysis\n",
        "s_lda = \"\"\"\\\n",
        "clf_lda = LinearDiscriminantAnalysis(n_components=5,priors=None)\n",
        "clf_lda.fit(data_train, label_train['symbols'].values)\n",
        "label_predicted_lda = clf_lda.predict(data_test)\n",
        "\"\"\"\n",
        "time_lda = timeit.timeit(stmt=s_lda, number=1000,globals=globals())\n",
        "print(time_lda)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5.956359138000153\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_vv-2_2PPuq",
        "outputId": "fbf283c1-b0aa-4ea7-b5bf-cbbdc7f6b27b"
      },
      "source": [
        "# QDA time performance analysis\n",
        "s_qda = \"\"\"\\\n",
        "clf_qda = QuadraticDiscriminantAnalysis(priors=None)\n",
        "clf_qda.fit(data_train, label_train['symbols'].values)\n",
        "label_predicted_qda = clf_qda.predict(data_test)\n",
        "\"\"\"\n",
        "time_qda = timeit.timeit(stmt=s_qda, number=1000,globals=globals())\n",
        "print(time_qda)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8.798752092000086\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Vr0WR_kPPk2",
        "outputId": "e5fbad5d-ae08-4974-8d18-52124fc8bd95"
      },
      "source": [
        "# SVM time performance analysis\n",
        "s_svm = \"\"\"\\\n",
        "support = svm.SVC()\n",
        "support.fit(data_train, label_train['symbols'].values)\n",
        "label_predicted_svm = support.predict(data_test)\n",
        "\"\"\"\n",
        "time_svm = timeit.timeit(stmt=s_svm, number=1000,globals=globals())\n",
        "print(time_svm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "182.54876726800012\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWmQsKk6PPN6",
        "outputId": "81183b9b-fc84-4307-9c48-47c8c2a232d4"
      },
      "source": [
        "# RF time performance analysis\n",
        "s_rf = \"\"\"\\\n",
        "forest = RandomForestClassifier()\n",
        "forest.fit(data_train, label_train['symbols'].values)              \n",
        "label_predicted_rf = forest.predict(data_test)\n",
        "\"\"\"\n",
        "time_rf = timeit.timeit(stmt=s_rf, number=10,globals=globals())\n",
        "print(time_rf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8.642775698999685\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqIUQPaBt473"
      },
      "source": [
        "**Conclusions:**\n",
        "- Performing the PCA analysis reduces the dimensionality of the data from 15 dimensions to 5 dimensions (91% of variability of data explained with 5 components)...\n",
        "- The accuracy of the classifiers is very good, in fact all the methods perform similarly. The best classifier is SVM with 5 components, achieving 99.18% of accuracy.\n",
        "- From the analysis of the TPR, FNR (true positive, etc.) we can conclude that... -> very good\n",
        "- Analyze performance time for each algorithm... how much time it takes to train and predict (use python function timeit)\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}