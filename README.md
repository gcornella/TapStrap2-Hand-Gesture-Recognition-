# TapStrap2-Hand-Gesture-Recognition-

The aim of this project is to present the Tap Strap hand-gestures device as an American Sign Language alphabet interpreter, by applying Machine Learning and Pattern Recognition techniques. A dimensionality reduction of the data set has been performed by PCA. Then, four classifiers have been trained using different techniques: LDA, QDA, SVM and Random Forest. Finally, the performance analysis of each classifier has been carried out, considering precision indices and time performances of the process of training and classification. 

The results obtained lead to the conclusion that for the scope of this project, SVM tends to be a more complete classifier. In addition to this, a Python script has been designed to test the alphabet recognition in real time in Ubuntu, with very good results.
